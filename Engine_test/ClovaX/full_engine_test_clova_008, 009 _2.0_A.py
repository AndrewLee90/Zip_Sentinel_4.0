import os, json, time, csv, requests, tempfile, pyzipper, re

# ‚öôÔ∏è Ïã§Ìñâ Î™®Îìú
MODE = "A"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_PATH = os.path.join(BASE_DIR, f"log_{MODE}.txt")
INPUT_JSON = os.path.join(BASE_DIR, f"inputs_test_1000_filled_final_{MODE}.json")
OUTPUT_CSV = os.path.join(BASE_DIR, f"engine_full_test_log_{MODE}.csv")
API_ENDPOINT = "Zipsentinel_Input_receiver"
AUTH_KEY = "Zipsentinel API KEY"

TIMEOUT = 180
SLEEP_INTERVAL = 30
MAX_MB = 30
RESULT_RE = re.compile(r"\[‚úÖ FE Ï†ÑÏÜ° Í≤∞Í≥º\] *(?P<json>\{.*\})")
LOG_MONITOR_PATH = os.path.join(BASE_DIR, "logs/zipsentinel.log")

def log(msg):
    print(msg, flush=True)
    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(msg + "\n")
        f.flush()

def get_inner_zip_under_30mb(zip_path, password="infected"):
    try:
        with pyzipper.AESZipFile(zip_path) as zf:
            zf.pwd = password.encode()
            files = [i for i in zf.infolist() if i.file_size / 1024 / 1024 < MAX_MB and i.filename.endswith((".zip", ".rar", ".7z", ".tar.gz"))]
            if files:
                chosen = sorted(files, key=lambda x: x.file_size)[0]
                out_path = os.path.join(tempfile.gettempdir(), os.path.basename(chosen.filename))
                with open(out_path, "wb") as f:
                    f.write(zf.read(chosen))
                return out_path, chosen.filename
    except Exception as e:
        log(f"[‚ö†Ô∏è ÎÇ¥Î∂Ä ZIP Ï∂îÏ∂ú Ïã§Ìå®] {e}")
    return None, None

def wait_for_result(post_id, timeout=TIMEOUT):
    start = time.time()
    while time.time() - start < timeout:
        try:
            with open(LOG_MONITOR_PATH, encoding="utf-8") as f:
                for line in reversed(f.readlines()):
                    if "[‚úÖ FE Ï†ÑÏÜ° Í≤∞Í≥º]" in line:
                        match = RESULT_RE.search(line)
                        if match:
                            try:
                                result_obj = json.loads(match.group("json").replace("'", '"'))
                                if result_obj.get("post_id") == post_id:
                                    return result_obj
                            except json.JSONDecodeError:
                                continue
        except FileNotFoundError:
            log(f"[‚ùå Î°úÍ∑∏ÌååÏùº ÏóÜÏùå] {LOG_MONITOR_PATH}")
        time.sleep(3)
    return {}

# ‚îÄ‚îÄ‚îÄ Î©îÏù∏ Ïã§Ìñâ ‚îÄ‚îÄ‚îÄ
with open(INPUT_JSON, encoding="utf-8") as f:
    tests = json.load(f)

with open(OUTPUT_CSV, "w", newline="", encoding="utf-8-sig") as csvf:
    writer = csv.writer(csvf)
    writer.writerow(["No", "post_id", "file_name", "analyzed", "risk_level", "malicious_count", "total_files", "vt_url", "elapsed_s", "status", "error"])

    for idx, test in enumerate(tests, 1):
        post_id = test["post_id"]
        post_text = test["post_text"]
        download_link = test["download_link"]
        t0 = time.time()
        analyzed = False
        result = {}
        error, status, file_name = "", "ÎØ∏ÏàòÌñâ", ""

        log(f"[{idx:04}] üì® Post ID={post_id} Îã§Ïö¥Î°úÎìú ÏãúÏûë")
        try:
            response = requests.get(download_link, stream=True, timeout=30)
            response.raise_for_status()
            temp_path = tempfile.NamedTemporaryFile(delete=False).name
            with open(temp_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            log(f"[{idx:04}] ‚úÖ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å: {round(os.path.getsize(temp_path)/(1024*1024), 2)}MB")

            inner_path, file_name = get_inner_zip_under_30mb(temp_path)
            if not inner_path:
                error = "Î∂ÑÏÑù Í∞ÄÎä•Ìïú ÎÇ¥Î∂ÄÌååÏùº ÏóÜÏùå"
                log(f"[{idx:04}] ‚ö†Ô∏è {error}")
                raise RuntimeError(error)

            log(f"[{idx:04}] üìÅ ÎÇ¥Î∂Ä ÌååÏùº Î∂ÑÏÑù ÎåÄÏÉÅ ÏÑ†ÌÉù ÏôÑÎ£å: {file_name}")

            res = requests.post(API_ENDPOINT,
                                headers={"Authorization": AUTH_KEY},
                                json={"post_id": post_id, "post_text": post_text, "download_link": download_link},
                                timeout=10)

            if res.status_code != 200:
                raise RuntimeError(f"API Ïò§Î•ò: {res.status_code}, {res.text}")

            result = wait_for_result(post_id, timeout=TIMEOUT)
            if result:
                analyzed = True
                status = result.get("status", "completed")
            else:
                raise TimeoutError("Í≤∞Í≥º ÏàòÏã† ÏãúÍ∞Ñ Ï¥àÍ≥º")

            risk = result.get("risk_level", "ÎØ∏Î∂ÑÏÑù")
            count = result.get("malicious_count", 0)
            total = result.get("total_files", 0)
            vturl = result.get("vt_report_url", "")

            log(f"[{idx:04}] üß† ÏóîÏßÑ ÌÖåÏä§Ìä∏ ÏÑ±Í≥µ: {risk} / ÏïÖÏÑ± {count}Í±¥")

        except Exception as e:
            risk, count, total, vturl = "ÏóêÎü¨", 0, 0, ""
            error = str(e)
            log(f"[{idx:04}] ‚ùå Ïã§Ìå®: {error}")

        elapsed = round(time.time() - t0, 2)
        writer.writerow([idx, post_id, file_name, "Y" if analyzed else "N", risk, count, total, vturl, elapsed, status, error])
        log(f"[{idx:04}] ‚úÖ ÌÖåÏä§Ìä∏ ÏôÑÎ£å")
        log(f"[{idx:04}] ‚è± Ï≤òÎ¶¨ ÏãúÍ∞Ñ : {elapsed}s\n")

        time.sleep(SLEEP_INTERVAL)
