import os, json, time, csv, requests, tempfile, pyzipper, re

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âš™ï¸ ì‹¤í–‰ ëª¨ë“œ ì„¤ì •: "A" ë˜ëŠ” "B"
MODE = "B"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

LOG_PATH = os.path.join(BASE_DIR, f"log_{MODE}.txt")
INPUT_JSON = os.path.join(BASE_DIR, f"inputs_test_1000_filled_final_{MODE}.json")
OUTPUT_CSV = os.path.join(BASE_DIR, f"engine_full_test_log_{MODE}.csv")
API_ENDPOINT = "Zipsentinel receiver"
AUTH_KEY = "Zipsentinel API KEY"  # MODEì— ë”°ë¼ êµì²´ ê°€ëŠ¥

TIMEOUT = 180
SLEEP_INTERVAL = 30
MAX_MB = 30
RESULT_RE = re.compile(r"\[âœ… FE ì „ì†¡ ê²°ê³¼\] *(?P<json>\{.*\})")
LOG_MONITOR_PATH = os.path.join(LOG_DIR, "zipsentinel.log")

# â”€â”€â”€ ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜ â”€â”€â”€
def log(msg):
    print(msg, flush=True)
    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(msg + "\n")
        f.flush()

# â”€â”€â”€ ë‚´ë¶€ ì••ì¶• íŒŒì¼ ì¶”ì¶œ â”€â”€â”€
def get_inner_zip_under_30mb(zip_path, password="infected"):
    try:
        with pyzipper.AESZipFile(zip_path) as zf:
            zf.pwd = password.encode()
            candidates = [i for i in zf.infolist() if i.file_size / 1024 / 1024 < MAX_MB and i.filename.endswith((".zip", ".rar", ".7z", ".tar.gz"))]
            if candidates:
                chosen = sorted(candidates, key=lambda x: x.file_size)[0]
                out_path = os.path.join(tempfile.gettempdir(), os.path.basename(chosen.filename))
                with open(out_path, "wb") as f:
                    f.write(zf.read(chosen))
                return out_path, chosen.filename
    except Exception as e:
        log(f"[âš ï¸ ë‚´ë¶€ ZIP ì¶”ì¶œ ì‹¤íŒ¨] {e}")
    return None, None

# â”€â”€â”€ ë¡œê·¸ì—ì„œ ê²°ê³¼ ê°ì‹œ â”€â”€â”€
def wait_for_result(post_id, timeout=TIMEOUT):
    start = time.time()
    while time.time() - start < timeout:
        try:
            with open(LOG_MONITOR_PATH, encoding="utf-8") as f:
                for line in reversed(f.readlines()):
                    if "[âœ… FE ì „ì†¡ ê²°ê³¼]" in line:
                        match = RESULT_RE.search(line)
                        if match:
                            try:
                                result_obj = json.loads(match.group("json").replace("'", '"'))
                                if result_obj.get("post_id") == post_id:
                                    return result_obj
                            except json.JSONDecodeError:
                                continue
        except FileNotFoundError:
            log(f"[âŒ ë¡œê·¸íŒŒì¼ ì—†ìŒ] {LOG_MONITOR_PATH}")
        time.sleep(3)
    return {}

# â”€â”€â”€ ë©”ì¸ ì‹¤í–‰ â”€â”€â”€
with open(INPUT_JSON, encoding="utf-8") as f:
    tests = json.load(f)

with open(OUTPUT_CSV, "w", newline="", encoding="utf-8-sig") as csvf:
    writer = csv.writer(csvf)
    writer.writerow(["No", "post_id", "file_name", "analyzed", "risk_level", "malicious_count", "total_files", "vt_url", "elapsed_s", "status", "error"])

    for idx, test in enumerate(tests, 1):
        post_id = test["post_id"]
        post_text = test["post_text"]
        download_link = test["download_link"]
        t0 = time.time()
        analyzed = False
        result = {}
        error, status, file_name = "", "ë¯¸ìˆ˜í–‰", ""

        log(f"[{idx:04}] ğŸ“¨ Post ID={post_id} ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        try:
            response = requests.get(download_link, stream=True, timeout=30)
            response.raise_for_status()
            temp_path = tempfile.NamedTemporaryFile(delete=False).name
            with open(temp_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            log(f"[{idx:04}] âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {round(os.path.getsize(temp_path)/(1024*1024), 2)}MB")

            inner_path, file_name = get_inner_zip_under_30mb(temp_path)
            if not inner_path:
                error = "ë¶„ì„ ê°€ëŠ¥í•œ ë‚´ë¶€íŒŒì¼ ì—†ìŒ"
                log(f"[{idx:04}] âš ï¸ {error}")
                raise RuntimeError(error)

            log(f"[{idx:04}] ğŸ“ ë‚´ë¶€ íŒŒì¼ ë¶„ì„ ëŒ€ìƒ ì„ íƒ ì™„ë£Œ: {file_name}")

            res = requests.post(API_ENDPOINT,
                                headers={"Authorization": AUTH_KEY},
                                json={"post_id": post_id, "post_text": post_text, "download_link": download_link},
                                timeout=10)
            if res.status_code != 200:
                raise RuntimeError(f"API ì˜¤ë¥˜: {res.status_code}, {res.text}")

            result = wait_for_result(post_id, timeout=TIMEOUT)
            if result:
                analyzed = True
                status = result.get("status", "completed")
            else:
                raise TimeoutError("ê²°ê³¼ ìˆ˜ì‹  ì‹œê°„ ì´ˆê³¼")

            risk = result.get("risk_level", "ë¯¸ë¶„ì„")
            count = result.get("malicious_count", 0)
            total = result.get("total_files", 0)
            vturl = result.get("vt_report_url", "")

            log(f"[{idx:04}] ğŸ§  ì—”ì§„ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {risk} / ì•…ì„± {count}ê±´")

        except Exception as e:
            risk, count, total, vturl = "ì—ëŸ¬", 0, 0, ""
            error = str(e)
            log(f"[{idx:04}] âŒ ì‹¤íŒ¨: {error}")

        elapsed = round(time.time() - t0, 2)
        writer.writerow([idx, post_id, file_name, "Y" if analyzed else "N", risk, count, total, vturl, elapsed, status, error])
        log(f"[{idx:04}] âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        log(f"[{idx:04}] â± ì²˜ë¦¬ ì‹œê°„ : {elapsed}s\n")

        time.sleep(SLEEP_INTERVAL)
